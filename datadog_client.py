"""
Datadog API Client
Handles communication with Datadog API for notebook operations
"""

import requests
import json
from typing import Dict, Any, Optional, List
import logging

logger = logging.getLogger(__name__)


class DatadogClient:
    def __init__(self, api_key: str, app_key: str, base_url: str = "https://api.datadoghq.com"):
        self.api_key = api_key
        self.app_key = app_key
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        self.session.headers.update({
            'DD-API-KEY': self.api_key,
            'DD-APPLICATION-KEY': self.app_key,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        })
    
    def create_notebook(self, notebook_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Create a notebook in Datadog
        
        Args:
            notebook_data: The notebook JSON structure
            
        Returns:
            Response from Datadog API
        """
        url = f"{self.base_url}/api/v1/notebooks"
        
        try:
            # Remove any read-only fields that shouldn't be in creation request
            clean_data = self._clean_notebook_data_for_creation(notebook_data)
            
            response = self.session.post(url, json=clean_data)
            response.raise_for_status()
            
            result = response.json()
            logger.info(f"Successfully created notebook: {result.get('data', {}).get('id', 'Unknown ID')}")
            return result
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to create notebook: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_details = e.response.json()
                    logger.error(f"API Error Details: {error_details}")
                    return {"error": error_details, "status_code": e.response.status_code}
                except:
                    logger.error(f"Response content: {e.response.text}")
                    return {"error": e.response.text, "status_code": e.response.status_code}
            return {"error": str(e), "status_code": None}
    
    def _clean_notebook_data_for_creation(self, notebook_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Clean notebook data by removing read-only fields for creation
        """
        clean_data = json.loads(json.dumps(notebook_data))  # Deep copy
        
        # Remove read-only fields
        attrs = clean_data.get("data", {}).get("attributes", {})
        
        # Remove fields that are set by the API
        read_only_fields = ["id", "created", "modified", "deleted", "author"]
        for field in read_only_fields:
            attrs.pop(field, None)
        
        # Remove id from data level as well
        clean_data.get("data", {}).pop("id", None)
        
        # Clean up cells - remove IDs as they're generated by API
        cells = attrs.get("cells", [])
        for cell in cells:
            cell.pop("id", None)
        
        return clean_data
    
    def get_notebook(self, notebook_id: str) -> Dict[str, Any]:
        """
        Get a notebook by ID
        
        Args:
            notebook_id: The notebook ID
            
        Returns:
            Notebook data or error information
        """
        url = f"{self.base_url}/api/v1/notebooks/{notebook_id}"
        
        try:
            response = self.session.get(url)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to get notebook {notebook_id}: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def list_notebooks(self, author_handle: Optional[str] = None, exclude_author_handle: Optional[str] = None,
                      start: int = 0, count: int = 5, sort_field: str = "modified", 
                      sort_dir: str = "desc") -> Dict[str, Any]:
        """
        List notebooks
        
        Args:
            author_handle: Filter by author handle
            exclude_author_handle: Exclude notebooks by author handle
            start: Starting index
            count: Number of notebooks to return
            sort_field: Field to sort by
            sort_dir: Sort direction (asc/desc)
            
        Returns:
            List of notebooks or error information
        """
        url = f"{self.base_url}/api/v1/notebooks"
        
        params = {
            "start": start,
            "count": count,
            "sort_field": sort_field,
            "sort_dir": sort_dir
        }
        
        if author_handle:
            params["author_handle"] = author_handle
        if exclude_author_handle:
            params["exclude_author_handle"] = exclude_author_handle
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to list notebooks: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def update_notebook(self, notebook_id: str, notebook_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a notebook
        
        Args:
            notebook_id: The notebook ID
            notebook_data: The updated notebook data
            
        Returns:
            Updated notebook data or error information
        """
        url = f"{self.base_url}/api/v1/notebooks/{notebook_id}"
        
        try:
            clean_data = self._clean_notebook_data_for_creation(notebook_data)
            response = self.session.put(url, json=clean_data)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to update notebook {notebook_id}: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def delete_notebook(self, notebook_id: str) -> Dict[str, Any]:
        """
        Delete a notebook
        
        Args:
            notebook_id: The notebook ID
            
        Returns:
            Success status or error information
        """
        url = f"{self.base_url}/api/v1/notebooks/{notebook_id}"
        
        try:
            response = self.session.delete(url)
            response.raise_for_status()
            return {"success": True, "status_code": response.status_code}
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to delete notebook {notebook_id}: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def test_connection(self) -> Dict[str, Any]:
        """
        Test the connection to Datadog API
        
        Returns:
            Connection status
        """
        try:
            # Try to list notebooks with a minimal request
            result = self.list_notebooks(count=1)
            if "error" not in result:
                return {"status": "connected", "message": "Successfully connected to Datadog API"}
            else:
                return {"status": "error", "message": f"Connection failed: {result['error']}"}
                
        except Exception as e:
            return {"status": "error", "message": f"Connection test failed: {str(e)}"}
    
    def validate_notebook_structure(self, notebook_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate notebook structure before creation
        
        Args:
            notebook_data: The notebook JSON structure
            
        Returns:
            Validation result
        """
        errors = []
        warnings = []
        
        try:
            # Check top-level structure
            if "data" not in notebook_data:
                errors.append("Missing 'data' field in notebook structure")
                return {"valid": False, "errors": errors, "warnings": warnings}
            
            data = notebook_data["data"]
            
            # Check data type
            if data.get("type") != "notebooks":
                errors.append("Data type must be 'notebooks'")
            
            # Check attributes
            if "attributes" not in data:
                errors.append("Missing 'attributes' field in data")
                return {"valid": False, "errors": errors, "warnings": warnings}
            
            attrs = data["attributes"]
            
            # Check required fields
            required_fields = ["name", "cells"]
            for field in required_fields:
                if field not in attrs:
                    errors.append(f"Missing required field: {field}")
            
            # Check cells structure
            if "cells" in attrs:
                cells = attrs["cells"]
                if not isinstance(cells, list):
                    errors.append("Cells must be a list")
                else:
                    for i, cell in enumerate(cells):
                        if "type" not in cell:
                            errors.append(f"Cell {i} missing 'type' field")
                        if "attributes" not in cell:
                            errors.append(f"Cell {i} missing 'attributes' field")
                        elif "definition" not in cell["attributes"]:
                            errors.append(f"Cell {i} missing 'definition' in attributes")
            
            # Check optional but recommended fields
            if "time" not in attrs:
                warnings.append("No time range specified, will use default")
            
            if "metadata" not in attrs:
                warnings.append("No metadata specified, will use defaults")
            
            return {
                "valid": len(errors) == 0,
                "errors": errors,
                "warnings": warnings
            }
            
        except Exception as e:
            return {
                "valid": False,
                "errors": [f"Validation error: {str(e)}"],
                "warnings": warnings
            }

    # Dashboard Methods
    def create_dashboard(self, dashboard_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Create a dashboard in Datadog
        
        Args:
            dashboard_data: The dashboard JSON structure
            
        Returns:
            Response from Datadog API
        """
        url = f"{self.base_url}/api/v1/dashboard"
        
        try:
            # Validate dashboard structure first
            validation_result = self.validate_dashboard_structure(dashboard_data)
            if not validation_result.get("valid", False):
                logger.error(f"Dashboard validation failed: {validation_result.get('errors', [])}")
                return {
                    "error": "Dashboard validation failed",
                    "validation_errors": validation_result.get("errors", []),
                    "status_code": 400
                }
            
            # Clean dashboard data for creation (removes deprecated fields)
            clean_data = self._clean_dashboard_data_for_creation(dashboard_data)
            
            logger.info(f"Creating dashboard with title: {clean_data.get('title', 'Untitled')}")
            logger.debug(f"Dashboard payload (cleaned): {json.dumps(clean_data, indent=2)}")
            
            response = self.session.post(url, json=clean_data)
            response.raise_for_status()
            
            result = response.json()
            dashboard_id = result.get('id', 'Unknown ID')
            logger.info(f"Successfully created dashboard with ID: {dashboard_id}")
            return result
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to create dashboard: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_details = e.response.json()
                    logger.error(f"API Error Details: {error_details}")
                    
                    # Check for specific deprecated field errors
                    if "errors" in error_details:
                        for error in error_details["errors"]:
                            if "is_read_only" in str(error).lower():
                                logger.error("The is_read_only field is deprecated. Please update your dashboard generation.")
                    
                    return {"error": error_details, "status_code": e.response.status_code}
                except json.JSONDecodeError:
                    logger.error(f"Response content: {e.response.text}")
                    return {"error": e.response.text, "status_code": e.response.status_code}
            return {"error": str(e), "status_code": None}
        except Exception as e:
            logger.error(f"Unexpected error creating dashboard: {str(e)}")
            return {"error": f"Unexpected error: {str(e)}", "status_code": 500}
    
    def _clean_dashboard_data_for_creation(self, dashboard_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Clean dashboard data by removing read-only and deprecated fields for creation
        """
        clean_data = json.loads(json.dumps(dashboard_data))  # Deep copy
        
        # Remove read-only and deprecated fields
        deprecated_and_readonly_fields = [
            "id", 
            "created_at", 
            "modified_at", 
            "author_handle", 
            "url",
            "is_read_only"  # Deprecated as of 2023
        ]
        
        for field in deprecated_and_readonly_fields:
            clean_data.pop(field, None)
        
        # Clean up widgets - remove IDs and other auto-generated fields
        widgets = clean_data.get("widgets", [])
        for widget in widgets:
            widget.pop("id", None)
            # Also clean definition level if it exists
            if "definition" in widget:
                widget["definition"].pop("id", None)
        
        # Ensure template_variables have proper structure
        template_vars = clean_data.get("template_variables", [])
        for var in template_vars:
            # Remove any auto-generated fields from template variables
            var.pop("id", None)
            # Ensure available_values is present for new template variable format
            if "available_values" not in var and "default" in var:
                var["available_values"] = ["*"]
        
        return clean_data
    
    def get_dashboard(self, dashboard_id: str) -> Dict[str, Any]:
        """
        Get a dashboard by ID
        
        Args:
            dashboard_id: The dashboard ID
            
        Returns:
            Dashboard data or error information
        """
        url = f"{self.base_url}/api/v1/dashboard/{dashboard_id}"
        
        try:
            response = self.session.get(url)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to get dashboard {dashboard_id}: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def list_dashboards(self, count: int = 10, start: int = 0, 
                       sort_field: str = "modified_at", sort_dir: str = "desc") -> Dict[str, Any]:
        """
        List dashboards
        
        Args:
            count: Number of dashboards to return (max 100)
            start: Starting index for pagination
            sort_field: Field to sort by
            sort_dir: Sort direction (asc/desc)
            
        Returns:
            List of dashboards or error information
        """
        url = f"{self.base_url}/api/v1/dashboard"
        
        params = {
            "count": min(count, 100),  # API limit
            "start": start,
            "sort_field": sort_field,
            "sort_dir": sort_dir
        }
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to list dashboards: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def update_dashboard(self, dashboard_id: str, dashboard_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a dashboard
        
        Args:
            dashboard_id: The dashboard ID
            dashboard_data: The updated dashboard data
            
        Returns:
            Updated dashboard data or error information
        """
        url = f"{self.base_url}/api/v1/dashboard/{dashboard_id}"
        
        try:
            clean_data = self._clean_dashboard_data_for_creation(dashboard_data)
            response = self.session.put(url, json=clean_data)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to update dashboard {dashboard_id}: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def delete_dashboard(self, dashboard_id: str) -> Dict[str, Any]:
        """
        Delete a dashboard
        
        Args:
            dashboard_id: The dashboard ID
            
        Returns:
            Success status or error information
        """
        url = f"{self.base_url}/api/v1/dashboard/{dashboard_id}"
        
        try:
            response = self.session.delete(url)
            response.raise_for_status()
            return {"success": True, "status_code": response.status_code}
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to delete dashboard {dashboard_id}: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}
    
    def validate_dashboard_structure(self, dashboard_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate dashboard structure before creation
        
        Args:
            dashboard_data: The dashboard JSON structure
            
        Returns:
            Validation result
        """
        errors = []
        warnings = []
        
        try:
            # Check required fields
            required_fields = ["title", "widgets", "layout_type"]
            for field in required_fields:
                if field not in dashboard_data:
                    errors.append(f"Missing required field: {field}")
            
            # Check layout_type
            layout_type = dashboard_data.get("layout_type")
            if layout_type:
                valid_layouts = ["ordered", "free"]
                if layout_type not in valid_layouts:
                    errors.append(f"Invalid layout_type. Must be one of: {', '.join(valid_layouts)}")
            
            # Check widgets structure
            if "widgets" in dashboard_data:
                widgets = dashboard_data["widgets"]
                if not isinstance(widgets, list):
                    errors.append("Widgets must be a list")
                else:
                    for i, widget in enumerate(widgets):
                        if "definition" not in widget:
                            errors.append(f"Widget {i} missing 'definition' field")
                        else:
                            widget_def = widget["definition"]
                            
                            # Check widget definition structure
                            if "type" not in widget_def:
                                errors.append(f"Widget {i} definition missing 'type' field")
                            
                            # Validate layout fields based on layout_type
                            if layout_type == "ordered":
                                if "layout" in widget:
                                    errors.append(f"Widget {i} should not have 'layout' field for ordered layout_type")
                            elif layout_type == "free":
                                if "layout" not in widget:
                                    errors.append(f"Widget {i} missing 'layout' field for free layout_type")
                                else:
                                    layout = widget["layout"]
                                    required_layout_fields = ["x", "y", "width", "height"]
                                    for field in required_layout_fields:
                                        if field not in layout:
                                            errors.append(f"Widget {i} layout missing '{field}' field")
                            
                            # Check widget requests
                            if "requests" in widget_def:
                                requests = widget_def["requests"]
                                if not isinstance(requests, list):
                                    errors.append(f"Widget {i} requests must be a list")
                                else:
                                    for j, request in enumerate(requests):
                                        if "q" not in request:
                                            errors.append(f"Widget {i} request {j} missing 'q' (query) field")
                            
                            # Check time configuration
                            if "time" not in widget_def:
                                warnings.append(f"Widget {i} missing 'time' configuration")
            
            # Check for deprecated fields
            deprecated_fields = ["is_read_only", "author_handle", "created_at", "modified_at", "url"]
            for field in deprecated_fields:
                if field in dashboard_data:
                    warnings.append(f"Field '{field}' is deprecated and will be removed")
            
            # Check optional but recommended fields
            if "description" not in dashboard_data:
                warnings.append("No description specified")
            
            if "template_variables" not in dashboard_data:
                warnings.append("No template variables specified")
            
            return {
                "valid": len(errors) == 0,
                "errors": errors,
                "warnings": warnings
            }
            
        except Exception as e:
            return {
                "valid": False,
                "errors": [f"Validation error: {str(e)}"],
                "warnings": warnings
            }

    def get_metrics_metadata(self, metric_name: Optional[str] = None) -> Dict[str, Any]:
        """
        Get metrics metadata from Datadog
        
        Args:
            metric_name: Optional specific metric name to get metadata for
            
        Returns:
            Metrics metadata or error information
        """
        url = f"{self.base_url}/api/v1/metrics"
        
        params = {}
        if metric_name:
            params["filter"] = metric_name
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to get metrics metadata: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}

    def get_active_metrics(self, from_timestamp: Optional[int] = None, 
                          host: Optional[str] = None, tag_filter: Optional[str] = None) -> Dict[str, Any]:
        """
        Get list of actively reporting metrics using Datadog API v2
        
        Args:
            from_timestamp: Start timestamp for active metrics
            host: Filter by host
            tag_filter: Filter by tags
            
        Returns:
            List of active metrics or error information
        """
        url = f"{self.base_url}/api/v2/metrics"
        
        params = {}
        if from_timestamp:
            params["from"] = from_timestamp
        if host:
            params["host"] = host
        if tag_filter:
            params["filter"] = tag_filter
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to get active metrics: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}

    def query_metrics(self, query: str, from_timestamp: int, to_timestamp: int) -> Dict[str, Any]:
        """
        Query metrics data
        
        Args:
            query: Metric query string
            from_timestamp: Start timestamp
            to_timestamp: End timestamp
            
        Returns:
            Query results or error information
        """
        url = f"{self.base_url}/api/v1/query"
        
        params = {
            "query": query,
            "from": from_timestamp,
            "to": to_timestamp
        }
        
        try:
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to query metrics: {str(e)}")
            return {"error": str(e), "status_code": getattr(e.response, 'status_code', None)}

    def get_integration_metrics(self, integration_name: str) -> List[str]:
        """
        Get list of metrics for a specific integration
        
        Args:
            integration_name: Name of the integration (e.g., 'aws', 'nginx', 'mysql')
            
        Returns:
            List of metric names for the integration
        """
        # This is a mapping of common integrations to their typical metrics
        # In a real implementation, this could be fetched from Datadog's documentation API
        integration_metrics = {
            "aws": [
                "aws.ec2.cpuutilization",
                "aws.ec2.diskreadbytes", 
                "aws.ec2.diskwritebytes",
                "aws.ec2.networkin",
                "aws.ec2.networkout",
                "aws.rds.cpuutilization",
                "aws.rds.database_connections",
                "aws.elb.request_count",
                "aws.elb.latency"
            ],
            "nginx": [
                "nginx.net.connections",
                "nginx.net.conn_opened_per_s",
                "nginx.net.conn_dropped_per_s",
                "nginx.net.request_per_s",
                "nginx.net.reading",
                "nginx.net.writing",
                "nginx.net.waiting"
            ],
            "mysql": [
                "mysql.performance.queries",
                "mysql.performance.questions",
                "mysql.performance.slow_queries",
                "mysql.performance.com_select",
                "mysql.performance.com_insert",
                "mysql.performance.com_update",
                "mysql.performance.com_delete",
                "mysql.innodb.buffer_pool_utilization",
                "mysql.innodb.current_row_locks"
            ],
            "redis": [
                "redis.info.connected_clients",
                "redis.info.used_memory",
                "redis.info.used_memory_rss", 
                "redis.info.mem_fragmentation_ratio",
                "redis.net.commands_processed",
                "redis.info.keyspace_hits",
                "redis.info.keyspace_misses",
                "redis.info.evicted_keys"
            ],
            "postgresql": [
                "postgresql.connections",
                "postgresql.commits",
                "postgresql.rollbacks",
                "postgresql.disk_read",
                "postgresql.buffer_hit",
                "postgresql.rows_returned",
                "postgresql.rows_fetched",
                "postgresql.rows_inserted",
                "postgresql.rows_updated",
                "postgresql.rows_deleted"
            ]
        }
        
        return integration_metrics.get(integration_name.lower(), [])

    def get_integration_documentation(self, integration_name: str, metric_name: str = None) -> Dict[str, str]:
        """
        Get documentation links for setting up integrations and metrics
        
        Args:
            integration_name: Name of the integration
            metric_name: Optional specific metric name
            
        Returns:
            Dictionary with documentation links and setup instructions
        """
        base_docs_url = "https://docs.datadoghq.com/integrations"
        
        # Documentation mapping for common integrations
        integration_docs = {
            "aws": {
                "setup_url": f"{base_docs_url}/amazon_web_services/",
                "metrics_url": f"{base_docs_url}/amazon_ec2/#metrics",
                "description": "Set up AWS integration to monitor EC2, RDS, ELB and other AWS services",
                "setup_steps": [
                    "Configure AWS IAM role with required permissions",
                    "Add AWS account to Datadog AWS integration",
                    "Enable specific AWS services you want to monitor"
                ]
            },
            "nginx": {
                "setup_url": f"{base_docs_url}/nginx/",
                "metrics_url": f"{base_docs_url}/nginx/#metrics",
                "description": "Configure Nginx integration to monitor web server performance",
                "setup_steps": [
                    "Enable nginx status module",
                    "Configure nginx.conf with status endpoint", 
                    "Install and configure Datadog agent",
                    "Update nginx.yaml configuration file"
                ]
            },
            "mysql": {
                "setup_url": f"{base_docs_url}/mysql/",
                "metrics_url": f"{base_docs_url}/mysql/#metrics",
                "description": "Set up MySQL integration for database monitoring",
                "setup_steps": [
                    "Create MySQL user for Datadog agent",
                    "Grant required permissions to the user",
                    "Configure mysql.yaml in agent configuration",
                    "Restart Datadog agent"
                ]
            },
            "redis": {
                "setup_url": f"{base_docs_url}/redisdb/",
                "metrics_url": f"{base_docs_url}/redisdb/#metrics", 
                "description": "Configure Redis integration for cache monitoring",
                "setup_steps": [
                    "Verify Redis INFO command access",
                    "Configure redisdb.yaml in agent configuration",
                    "Set up authentication if Redis requires it",
                    "Restart Datadog agent"
                ]
            },
            "postgresql": {
                "setup_url": f"{base_docs_url}/postgres/",
                "metrics_url": f"{base_docs_url}/postgres/#metrics",
                "description": "Set up PostgreSQL integration for database monitoring", 
                "setup_steps": [
                    "Create PostgreSQL user for Datadog agent",
                    "Grant required permissions and access to pg_stat_* views",
                    "Configure postgres.yaml in agent configuration",
                    "Restart Datadog agent"
                ]
            }
        }
        
        return integration_docs.get(integration_name.lower(), {
            "setup_url": f"{base_docs_url}/{integration_name.lower()}/",
            "description": f"Set up {integration_name} integration",
            "setup_steps": [
                "Check Datadog documentation for specific setup instructions",
                "Configure integration in Datadog agent",
                "Restart agent after configuration"
            ]
        }) 